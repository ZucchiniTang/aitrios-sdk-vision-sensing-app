= Vision and Sensing Application SDK pass:[<br/>] In a Day pass:[<br/>] Functional Specifications pass:[<br/>]
:sectnums:
:sectnumlevels: 1
:author: Copyright 2023 Sony Semiconductor Solutions Corporation
:version-label: Version 
:revnumber: x.x.x
:revdate: YYYY - MM - DD
:trademark-desc1: AITRIOSâ„¢ and AITRIOS logos are the registered trademarks or trademarks
:trademark-desc2: of Sony Group Corporation or its affiliated companies.
:toc:
:toc-title: TOC
:toclevels: 1
:chapter-label:
:lang: en

== Change history

|===
|Date |What/Why

|2023/05/26
|Initial draft.

|===

== Terms/Abbreviations
|===
|Terms/Abbreviations |Meaning 

|TFRecord
|A type of TensorFlow dataset format

|SavedModel
|A type of neural network format

|TFLite
|TensorFlow Lite + 
A _.tflite_ model is a type of neural network format

|Wasm
|WebAssembly. Binary instruction format for virtual machines

|IoU
|Intersection over Union. The degree to which regions overlap

|SAS
|Shared Access Signatures +
URI that grant limited access to Azure storage resources

|"**Zone Detection**"
|Sample application provided by "**Cloud SDK**"

|"**Console Access Library**"
|Libraries for using the features of the "**Console REST API**". There is one for Python and another for TypeScript, but for the purposes of this document, it is meant for Python.

|Deployment configuration
|Used to deploy AI models. + 
 Specify the AI model to deploy, etc. and register it in "**Console for AITRIOS**". + 
Run a deployment by specifying a registered deployment configuration. + 
Note that it is separate from the `**configuration.json**` to configure notebook runtime settings.

|"**PPL**"
|A module that processes the output of the AI model(Output Tensor) of edge AI devices

|PPL parameter
|Parameters used to initialize the "**PPL**" library

|Inference result metadata
|Data output by "**PPL**"

|Command Parameter File
|json file used to apply PPL parameter to devices

|Sample images
|Images taken with an edge AI device as a sample of "**Zone Detection**" stored in the "**Cloud SDK**" GitHub repository

|===

== Reference materials

* Reference/Related documents
** TensorFlow 1 Detection Model Zoo
*** https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md

** Colab tutorials for Coral
*** https://github.com/google-coral/tutorials.git

** API Reference
*** https://developer.aitrios.sony-semicon.com/development-guides/reference/api-references/

== Expected use case

* To give you an overview of the SDK in a day, let you run a series of SDK workflows in the single notebook, using the example of the sample application "**Zone Detection**" + 
However, parts you can't run on Codespaces provide documentation instead

== Functional overview/Algorithm

=== Functional overview

* In the following flow, using the sample application "**Zone Detection**" as an example, the features provided by the SDK can be performed in the single notebook

* It is recommended to run the cell of the notebook one by one

* Indicates approximate time for notebook cells that take longer

* SDK includes backup data of CVAT project annotating images taken with an edge AI device as a sample of "**Zone Detection**"

* SDK includes a TFRecord format dataset annotated with images taken with an edge AI device as a sample of "**Zone Detection**"

* Users can create quantized AI models of Object Detection by transfer learning on SDK as an alternative to the procedures of creating AI models on "**Console for AITRIOS**" for "**Zone Detection**"

* Users can run inference on quantized AI models that are transfer learned on SDK and output Output Tensor information

* Users can build "**PPL**", edit PPL parameter information, use Output Tensor information to debug "**PPL**" and output serialized inference result metadata

* Users can deserialize serialized inference result metadata and display images overlaid with inference results

* Users can import transfer learned quantized AI models and "**PPL**" into "**Console for AITRIOS**" and deploy them to devices

* The base AI model used by the SDK is ssd_mobilenet_v1_quantized_coco from TensorFlow 1 Detection Model Zoo

* The image format supported by the SDK is JPEG

* Flow overview

[mermaid, target="Legend"]
----
flowchart TD;
    %% definition
    classDef object fill:#FFE699, stroke:#FFD700
    style legend fill:#FFFFFF, stroke:#000000

    %% impl
    subgraph legend["Legend"]
        process(Processing/User behavior)
    end
----

[mermaid, target="Flow overview"]
----
flowchart TD
    start((Start)) --> id1(1.Prepare images to use as input)
    id1 --> id2(2.Prepare an AI model on which to base transfer learning, evaluate it and display images overlaid with inference results)
    id2 --> id3(3.Perform transfer learning, evaluate it and display images overlaid with inference results)
    id3 --> id4(4.Build and run PPL and display images overlaid with inference results)
    id4 --> id5(5.Edit PPL parameter and run PPL to display images overlaid with inference results)
    id5 --> id6(6.Upload AI model to Blob Storage)
    id6 --> id7(7.Import AI model and PPL into Console for AITRIOS and deploy it to devices)
    id7 --> finish(((Finish)))
----

* Flow details

. Prepare images to use as input

** Extract the zip file containing sample images taken with an edge AI device stored in the "**Cloud SDK**" GitHub repository

. Prepare an AI model on which to base transfer learning, evaluate it and display images overlaid with inference results

** Download a quantized AI model on which to base transfer learning
** Evaluate an AI model before transfer learning using a dataset of sample images and display sample images overlaid with inference results

. Perform transfer learning, evaluate it and display images overlaid with inference results

** Originally in "**Zone Detection**" an AI model is created in "**Console for AITRIOS**" using the base AI model of "**Console for AITRIOS**" and used in the device, but since the AI model created in "**Console for AITRIOS**" can not be exported to the SDK, an AI model is created in the SDK for this notebook
** Create a Docker image for transfer learning
** Create an AI model by transfer learning using a dataset of sample images and quantizing
** Evaluate a transfer learned AI model using a dataset of sample images, and save inference results as Output Tensor (data similar to when the AI model is run on a physical IMX500 device)
** Display sample images overlaid with inference results

. Build and run "**PPL**" and display images overlaid with inference results

** Provides an overview of "**PPL**", PPL parameters and Serialization
** Build "**PPL**"
** Run "**PPL**" using Output Tensor and pre-edited PPL parameter to get serialized inference result metadata
** Deserialize inference result metadata
** Display sample images overlaid with inference results

. Edit PPL parameter and run "**PPL**" to display images overlaid with inference results

** Run "**PPL**" using Output Tensor and edited PPL parameter to get serialized inference result metadata
** Deserialize inference result metadata
** Display sample images overlaid with inference results

. Upload AI model to Blob Storage

** Provides an overview of "**Console for AITRIOS**"
** Provides a link to the procedure for uploading a transfer learned AI model to Blob Storage

. Import AI model and "**PPL**" into "**Console for AITRIOS**" and deploy it to devices

** Set parameters such as AI model, "**PPL**" and ID of the devices to import into "**Console for AITRIOS**"
** Import AI model and "**PPL**" into "**Console for AITRIOS**" using "**Console Access Library**"
** Deploy AI model and "**PPL**" to devices using "**Console Access Library**"
** Explains how to create a Command Parameter File and import it into "**Console for AITRIOS**" and apply it to devices

== User interface specifications
=== How to start each function
. Launch the SDK environment and preview the `**README.md**` in the top directory
. Jump to the `**README.md**` in the `**samples**` directory from the hyperlink in the SDK environment top directory.
. Jump to the `**README.md**` in the `**zone_detection**` directory from the hyperlink in the `**README.md**` in the `**samples**` directory
. Jump to the `**README.md**` in the `**sdk_in_a_day.ipynb**` directory from the hyperlink in the `**README.md**` in the `**zone_detection**` directory

=== Prepare images to use as input
. Extract the zip file containing sample images taken with an edge AI device stored in the "**Cloud SDK**" GitHub repository to the directory `**dataset/images/training**` and `**dataset/images/validation**`

=== Prepare an AI model on which to base transfer learning, evaluate it and display images overlaid with inference results
. Download a quantized AI model on which to base transfer learning

** Download an AI model on which to base transfer learning (TensorFlow 1 Detection Model Zoo ssd_mobilenet_v1_quantized_coco) to the directory `**models/out/ckpt**`

. Evaluate an AI model before transfer learning using a dataset of sample images, and display images overlaid with inference results

** Displays sample images overlaid with the bounding box of the inference result and Accuracy (%) (Results in low accuracy because of pre-transfer learning)

=== Perform transfer learning, evaluate it and display images overlaid with inference results

. Create a Docker image for transfer learning

. Create an AI model by transfer learning using a dataset of sample images and quantizing

** Perform transfer learning using a dataset of sample images and save the AI model in the directory `**models/out/train**`

** AI model in SavedModel format, quantized at the same time as transfer learning by Quantization Aware Training (QAT), is saved as intermediate products in the directory `**models/out/models**`
** The intermediate product is converted to an AI model in TFLite format and saved as: `**models/model_quantized_od.tflite**`

. Evaluate a transfer learned AI model (TFLite) using a dataset of sample images, and save inference results as Output Tensor

** Saves inference results as a file, `**application/output_tensor.jsonc**`

. Display images overlaid with inference results

** Displays sample images overlaid with the bounding box of the inference result and Accuracy (%) (Results in high accuracy because of post-transfer learning)

=== Build and run "**PPL**" and display images overlaid with inference results

. Provides an overview of "**PPL**" and PPL parameter

** "**PPL**" for "**Zone Detection**" was created based on the sample code for "**PPL**" for Object Detection provided by the SDK, and it is possible to set the threshold value for detecting objects using PPL parameter, and to specify a zone detection area using PPL parameter to determine whether objects are in the zone detection area

. Build "**PPL**"

** Generates the Wasm file as an `**application/vision_app_zonedetection.wasm**`

. Run "**PPL**" using Output Tensor and pre-edited PPL parameter to get serialized inference result metadata

** Use the pre-edited PPL parameter saved as `**application/ppl_parameter_before.json**`
** Saves serialized inference result metadata as `**deserialize/ppl_output_before.bin**`

. Deserialize inference result metadata

** Saves deserialized inference result metadata as `**deserialize/ppl_output_before.json**`

. Display sample images overlaid with inference results

** Displays sample images overlaid with the bounding box of the inference result, Accuracy (%), IoU (%) and the bounding box of the zone detection area

=== Edit PPL parameter and run "**PPL**" to display images overlaid with inference results

. Run "**PPL**" using Output Tensor and edited PPL parameter to get serialized inference result metadata

** Edit the object detection threshold of the PPL parameter, save it as `**application/ppl_parameter_after.json**`, and use it
** Saves serialized inference result metadata as `**deserialize/ppl_output_after.bin**`

. Deserialize inference result metadata

** Saves deserialized inference result metadata as `**deserialize/ppl_output_after.json**`

. Display sample images overlaid with inference results

** Displays sample images overlaid with the bounding box of the inference result, Accuracy (%), IoU (%) and the bounding box of the zone detection area

=== Upload AI model to Blob Storage

. Provides a link to the procedure for uploading a transfer learned AI model to Blob Storage

=== Import AI model and "**PPL**" into "**Console for AITRIOS**" and deploy it to devices

. Provides a link to the procedures on how to register and participate in AITRIOS projects from "**Portal for AITRIOS**"

. Set parameters such as AI model, "**PPL**" and ID of the devices to import into "**Console for AITRIOS**"

** Create a new configuration file, `**tutorials/_common/set_up_console_client/configuration.json**`, in the SDK runtime environment and set each parameter
+
[cols="1,1,1,1a"]
|===
|Configuration |Meaning |Range |Remarks

|`**console_endpoint**`
|API server base URL
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate +
Used for the following "**Console Access Library**" API.

* `**common.config.Config**`

|`**portal_authorization_endpoint**`
|Authentication server URL
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate +
Used for the following "**Console Access Library**" API.

* `**common.config.Config**`

|`**client_id**`
|Client ID required for authentication
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate +
Used for the following "**Console Access Library**" API.

* `**common.config.Config**`

|`**client_secret**`
|Secret required for authentication
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate +
Used for the following "**Console Access Library**" API.

* `**common.config.Config**`

|===

** Create a new configuration file, `**configuration.json**`, and set each parameter
+
NOTE: All values are case sensitive, unless otherwise indicated.
+
NOTE: Do not use symbolic links to files and directories.
+

|===
|Configuration |Meaning |Range |Remarks

|`**import_model**`
|Configurations for importing AI models
|See the <<import_model>>
|Don't abbreviate

|`**import_app**`
|Configurations for importing "**PPL**"
|See the <<import_app>>
|Don't abbreviate

|`**deploy_model**`
|Settings for deploying AI models
|See the <<deploy_model>>
|Don't abbreviate

|`**deploy_app**`
|Settings for deploying "**PPL**"
|See the <<deploy_app>>
|Don't abbreviate

|`**command_parameter_file_name**`
|File name of the Command Parameter File to save on the SDK execution environment
|String
|Don't abbreviate

|===

*** import_model [[import_model]]
+
[cols="1,1,1,1a"]
|===
|Configuration |Meaning |Range |Remarks

|`**model_id**`
|ID of AI model to import +
 +
If it is a new ID, it is newly registered. +
Upgrade if it is a registered ID.
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate +
Used for the following "**Console Access Library**" API.

* `**ai_model.ai_model.AIModel.import_base_model**`
* `**ai_model.ai_model.AIModel.get_base_model_status**`
* `**ai_model.ai_model.AIModel.publish_model**`

|`**model**`
|SAS URI for AI model to import
|SAS URI format +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate +
Used for the following "**Console Access Library**" API.

* `**ai_model.ai_model.AIModel.import_base_model**`

|`**vendor_name**`
|Vendor name + 
(specify for new registration)
|String +
Details follow the "**Console Access Library**" API specification.
|Optional +
If omitted, no vendor name +
Used for the following "**Console Access Library**" API.

* `**ai_model.ai_model.AIModel.import_base_model**`

|`**comment**`
|AI model and version description +
 +
AI model and version description for new registrations, +
Set as description of version when upgrading
|String +
Details follow the "**Console Access Library**" API specification.
|Optional +
If omitted, no description +
Used for the following "**Console Access Library**" API.

* `**ai_model.ai_model.AIModel.import_base_model**`

|`**labels**`
|Label name +
 +
For Custom Vision, set the contents of the label.txt file that comes with the AI model file
|["label01","label02","label03"] +
Details follow the "**Console Access Library**" API specification.
|Optional +
Used for the following "**Console Access Library**" API.

* `**ai_model.ai_model.AIModel.import_base_model**`

|===

*** import_app [[import_app]]
+
[cols="1,1,1,1a"]
|===
|Configuration |Meaning |Range |Remarks

|`**ppl_file**`
|"**PPL**" file path
|Absolute path or relative to the notebook (*.ipynb)
|Don't abbreviate


|`**app_name**`
|"**PPL**" name
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate +
Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.import_device_app**`

|`**version_number**`
|"**PPL**" version
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate +
Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.import_device_app**`

|`**comment**`
|"**PPL**" description
|String +
Details follow the "**Console Access Library**" API specification.
|Optional +
If omitted, no comment +
Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.import_device_app**`

|===

*** deploy_model [[deploy_model]]
+
[cols="1,1,1a,1a,1a"]
|===
|Configuration | |Meaning |Range |Remarks

|`**should_create_deploy_config**`
|
|Whether to register new deployment configuration
|true or false +
true:New registration +
false:Use registered
|Don't abbreviate

|`**config_id**`
|
|ID of the deployment configuration

* Specify any character string for new registration
* If using registered, specify its ID

|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.create_deploy_configuration**`
* `**deployment.deployment.Deployment.deploy_by_configuration**`

|`**create_config**`
|`**comment**`
|Description of the newly registered deployment configuration|String +
Details follow the "**Console Access Library**" API specification.
|Optional

* Use to register a new deployment configuration.

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.create_deploy_configuration**`

|
|`**model_id**`
|ID of the AI model to deploy +
Specify the ID of an imported AI model
|String +
Details follow the "**Console Access Library**" API specification.
|Optional. But don't abbreviate this to register a new deployment configuration.

* Use to register a new deployment configuration.

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.create_deploy_configuration**`

|
|`**model_version_number**`
|Version of the AI model to deploy +
Specify the version of an imported AI model
|String +
Details follow the "**Console Access Library**" API specification.
|Optional

* Use to register a new deployment configuration.

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.create_deploy_configuration**`

|`**device_ids**`
|
|ID of the edge AI devices to deploy AI model
|List of strings
|Don't abbreviate

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.deploy_by_configuration**`

|`**replace_model_id**`
|
|ID of the AI model to be replaced + 
Specify the ID of the AI model to replace (overwrite) among the models deployed on the device
|String +
Details follow the "**Console Access Library**" API specification.
|Optional +
Optional if you don't replace the AI model. + 
(If not specified when the number of models deployed on the edge AI device has reached the limit, an error occurs.)

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.deploy_by_configuration**`

|`**comment**`
|
|Deployment description
|String +
Details follow the "**Console Access Library**" API specification.
|Optional

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.deploy_by_configuration**`

|===

*** deploy_app [[deploy_app]]
+
[cols="1,1,1,1a"]
|===
|Configuration |Meaning |Range |Remarks

|`**app_name**`
|Name of the "**PPL**" to deploy
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.deploy_device_app**`
* `**deployment.deployment.Deployment.get_device_app_deploys**`

|`**version_number**`
|Version of the "**PPL**" to deploy
|String +
Details follow the "**Console Access Library**" API specification.
|Don't abbreviate

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.deploy_device_app**`
* `**deployment.deployment.Deployment.get_device_app_deploys**`

|`**device_ids**`
|ID of edge AI device to deploy "**PPL**"
|List of strings
|Don't abbreviate

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.deploy_device_app**`

|`**comment**`
|"**PPL**" deployment description
|String +
Details follow the "**Console Access Library**" API specification.
|Optional

Used for the following "**Console Access Library**" API.

* `**deployment.deployment.Deployment.deploy_device_app**`

|===

. Import AI model and "**PPL**" into "**Console for AITRIOS**" using "**Console Access Library**"

. Deploy AI model and "**PPL**" to devices using "**Console Access Library**"

. Create a Command Parameter File

. Explains how to import a Command Parameter File into "**Console for AITRIOS**" and apply it to a device

=== Supplement

** If an error occurs in external software, for example, TensorFlow, the error output by the external software is displayed and running is interrupted.
** Displays logs from TensorFlow library while AI model is transfer learning and running inference
** While processing, you can interrupt with the Stop Cell Execution of notebook cell function.

== Target performances/Impact on performances
** When the SDK environment is built, users can run the notebook without any additional installation steps
** UI response time of 1.2 seconds or less
** If processing takes more than 5 seconds, indicates that processing is in progress with successive updates

== Assumption/Restriction
* Depending on the size of the dataset, even if Codespaces has a Machine Type of 4-core, an error will occur due to insufficient memory during transfer learning. In this case, select a Machine Type of 8-core or higher

== Remarks
* About how to check OSS library versions
** See the Dockerfile of the transfer learning container

* Source code for transfer learning that modifies a part of OSS to incorporate it into the SDK for use (Dockerfile, etc.)
** Colab tutorials for Coral

* OSS library used in transfer learning container
** TensorFlow v 1.15.5 source code
** TensorFlow Model Garden f788046ca876a8820e05b0b48c1fc2e16b0955bc source code
** Python apt package
** Tkinter apt package
** Git apt package
** Curl apt package
** Unzip apt package
** Cython PyPI package
** Contextlib2PyPI package
** Pillow PyPI package
** lxml PyPI package
** Jupyter PyPI package
** Matplotlib PyPI package
** Protocol Buffer Compiler v 3.0.0 binary
** COCO API source code

* OSS libraries used by the notebook
** Matplotlib
** OpenCV
** NumPy
** TensorFlow

== Unconfirmed items

None
