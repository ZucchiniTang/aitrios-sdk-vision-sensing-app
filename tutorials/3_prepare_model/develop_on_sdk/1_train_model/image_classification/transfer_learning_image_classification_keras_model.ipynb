{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022-2023 Sony Semiconductor Solutions Corp. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning (Image Classification Keras Model)\n",
    "\n",
    "This notebook explains the workflow to train AI model using transfer learning with Keras.\n",
    "\n",
    "Instructions are described in [README.md](./README.md)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear cache\n",
    "Clear cache including all modules, variables and history to free up RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%sx sync && echo 3 | sudo tee /proc/sys/vm/drop_caches > /dev/null"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import errno\n",
    "import glob\n",
    "import json\n",
    "import jsonschema\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configurations\n",
    "\n",
    "Load the configuration file and set the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_symlink(path: pathlib.Path):\n",
    "    if path.is_symlink():\n",
    "        raise OSError(\n",
    "            errno.ELOOP,\n",
    "            \"Symbolic link is not supported. Please use real folder or file\",\n",
    "            f\"{path}\",\n",
    "        )\n",
    "\n",
    "\n",
    "configuration_path = pathlib.Path(\"./configuration.json\")\n",
    "validate_symlink(configuration_path)\n",
    "\n",
    "with open(configuration_path, \"r\") as f:\n",
    "    app_configuration = json.load(f)\n",
    "\n",
    "configuration_schema_path = pathlib.Path(\"./configuration_schema.json\")\n",
    "validate_symlink(configuration_schema_path)\n",
    "\n",
    "with open(configuration_schema_path, \"r\") as f:\n",
    "    json_schema = json.load(f)\n",
    "\n",
    "jsonschema.validate(app_configuration, json_schema)\n",
    "\n",
    "source_keras_model = app_configuration.get(\"source_keras_model\", \"\")\n",
    "if source_keras_model:\n",
    "    validate_symlink(pathlib.Path(source_keras_model))\n",
    "\n",
    "dataset_training_dir = app_configuration[\"dataset_training_dir\"].replace(\n",
    "    os.path.sep, \"/\"\n",
    ")\n",
    "validate_symlink(pathlib.Path(dataset_training_dir))\n",
    "\n",
    "dataset_validation_dir = app_configuration[\"dataset_validation_dir\"].replace(\n",
    "    os.path.sep, \"/\"\n",
    ")\n",
    "validate_symlink(pathlib.Path(dataset_validation_dir))\n",
    "\n",
    "evaluate_label_file = app_configuration[\"evaluate_label_file\"].replace(os.path.sep, \"/\")\n",
    "validate_symlink(pathlib.Path(evaluate_label_file))\n",
    "\n",
    "batch_size = app_configuration[\"batch_size\"]\n",
    "\n",
    "input_tensor_size = app_configuration[\"input_tensor_size\"]\n",
    "\n",
    "epochs = app_configuration[\"epochs\"]\n",
    "\n",
    "output_dir = app_configuration[\"output_dir\"].replace(os.path.sep, \"/\")\n",
    "validate_symlink(pathlib.Path(output_dir))\n",
    "\n",
    "evaluate_result_dir = app_configuration[\"evaluate_result_dir\"].replace(os.path.sep, \"/\")\n",
    "validate_symlink(pathlib.Path(evaluate_result_dir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Load training/validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(evaluate_label_file) as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = input_tensor_size\n",
    "img_width = input_tensor_size\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_training_dir, image_size=(img_height, img_width), batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_validation_dir, image_size=(img_height, img_width), batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(train_ds.class_names)\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (normalization_layer(x), y)\n",
    ")  # Where x—images, y—labels.\n",
    "val_ds = val_ds.map(\n",
    "    lambda x, y: (normalization_layer(x), y)\n",
    ")  # Where x—images, y—labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your dataset is small and you want to improve learning performance,\n",
    "# please enable following lines to cache in memory and prefetch.\n",
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning AI Model\n",
    "\n",
    "Load base AI Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not source_keras_model:\n",
    "    IMG_SIZE = (input_tensor_size, input_tensor_size)\n",
    "    IMG_SHAPE = IMG_SIZE + (3,)\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=IMG_SHAPE, include_top=False, weights=\"imagenet\"\n",
    "    )\n",
    "else:\n",
    "    if os.path.isfile(source_keras_model):\n",
    "        # earlier style keras h5 file\n",
    "        base_model = tf.keras.models.load_model(source_keras_model)\n",
    "    else:\n",
    "        # later style keras SavedModel folder\n",
    "        base_model = tf.keras.models.load_model(source_keras_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove top (output) layer if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If base_model includes top (output) layer, we must remove the top (output) layer. For example:\n",
    "# remove_top_layer_if_needed START\n",
    "# if source_keras_model:\n",
    "#     top_layer_offset = -3\n",
    "#     base_model = tf.keras.Model(base_model.layers[0].input,\n",
    "#                                 base_model.layers[top_layer_offset].output)\n",
    "# remove_top_layer_if_needed END"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create AI Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(input_tensor_size, input_tensor_size, 3))\n",
    "\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# A Dense classifier with a number of classes\n",
    "outputs = tf.keras.layers.Dense(\n",
    "    num_classes,\n",
    "    activation=\"softmax\",\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(image_batch)\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1\n",
    ")  # Enable histogram computation for every epoch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AI Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=epochs, callbacks=tensorboard_callback\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training result.\n",
    "\n",
    "By executing following cell, tensorboard starts hosting. To display the tensorboard, in VS Code PORTS tab, open the port (like 6006) in the web browser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = os.path.join(output_dir, \"saved_model\")\n",
    "\n",
    "model.save(export_path)\n",
    "\n",
    "export_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate saved AI Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras model\n",
    "reloaded = tf.keras.models.load_model(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate using AI models before/after saving to file system\n",
    "result_batch = model.predict(image_batch)\n",
    "reloaded_result_batch = reloaded.predict(image_batch)\n",
    "\n",
    "# check the result is the same (the diff is 0.0).\n",
    "abs(reloaded_result_batch - result_batch).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_predicted_id = tf.math.argmax(reloaded_result_batch, axis=-1)\n",
    "reloaded_predicted_label_batch = class_names[reloaded_predicted_id]\n",
    "\n",
    "correct_count = 0\n",
    "for idx, label in enumerate(labels_batch):\n",
    "    if np.int64(label) == reloaded_predicted_id[idx]:\n",
    "        correct_count += 1\n",
    "accuracy = correct_count / len(labels_batch)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: If you want to use evaluate() method of Keras model, you can run as following:\n",
    "# top_1_accuracy = reloaded.evaluate(val_ds)[1]\n",
    "# print(f'\\nTop1 accuracy: {top_1_accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumerate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split(r\"(\\d+)\", text)]\n",
    "\n",
    "\n",
    "files_all = sorted(\n",
    "    glob.glob(f\"{dataset_validation_dir}/**/*.*\", recursive=True), key=natural_keys\n",
    ")\n",
    "\n",
    "folders = sorted(\n",
    "    glob.glob(f\"{dataset_validation_dir}/*/\", recursive=True), key=natural_keys\n",
    ")\n",
    "\n",
    "# get images and ground truth for evaluation\n",
    "test_images = []\n",
    "ground_truth_ids = []\n",
    "for folder in folders:\n",
    "    files_in_folder = sorted(\n",
    "        glob.glob(os.path.join(folder, \"*.*\"), recursive=True), key=natural_keys\n",
    "    )\n",
    "    for file in files_in_folder:\n",
    "        label = os.path.basename(os.path.dirname(file))\n",
    "        if label in labels:\n",
    "            label_id = labels[label]\n",
    "            filename = os.path.basename(file)\n",
    "            info = dict()\n",
    "            info[\"path\"] = file\n",
    "            info[\"imageID\"] = filename\n",
    "            test_images.append(info)\n",
    "            ground_truth_ids.append(label_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define evaluate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_keras_model(model, images, ground_truth):\n",
    "    def load_image(image_path):\n",
    "        image = tf.io.decode_jpeg(tf.io.read_file(image_path), channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        # image = tf.image.central_crop(image, central_fraction=0.875)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        image = tf.compat.v1.image.resize_bilinear(\n",
    "            image, [input_tensor_size, input_tensor_size], align_corners=False\n",
    "        )\n",
    "        image = tf.squeeze(image, [0])\n",
    "        return image\n",
    "\n",
    "    image_paths = []\n",
    "    for test_image in images:\n",
    "        image_paths.append(test_image[\"path\"])\n",
    "    images_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        [str(path) for path in image_paths]\n",
    "    ).map(load_image)\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        np.array(ground_truth).astype(np.uint32)\n",
    "    )\n",
    "    test_data = tf.data.Dataset.zip((images_ds, labels_ds)).shuffle(len(image_paths))\n",
    "\n",
    "    model.trainable = False\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    test_result = model.evaluate(test_data.batch(1))\n",
    "\n",
    "    return test_result[1]  # Top1 accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1_accuracy = evaluate_keras_model(reloaded, test_images, ground_truth_ids)\n",
    "print(f\"\\nTop1 accuracy: {top_1_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save evaluation results as **`results.json`** in **`evaluate_result_dir`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_output_dir = pathlib.Path(evaluate_result_dir)\n",
    "evaluate_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with open(evaluate_output_dir / \"results.json\", \"w\") as f:\n",
    "    results = dict()\n",
    "    results[\"top_1_accuracy\"] = top_1_accuracy\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear cache\n",
    "Clear cache including all modules, variables and history to free up RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%sx sync && echo 3 | sudo tee /proc/sys/vm/drop_caches > /dev/null"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
